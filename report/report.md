# ğŸš¢ Portafolio de Ciencia de Datos â€“ Proyecto Titanic

* **Nombre:** Francisco Alfaro
* **Curso:** Fundamentos de Ciencia de Datos
* **Fecha:** Junio 2025
* **Repositorio GitHub:** [https://github.com/fralfaro/titanic-portfolio](https://github.com/fralfaro/titanic-portfolio)



## ğŸ“Œ Resumen Ejecutivo

Este portafolio documenta el anÃ¡lisis completo del dataset del Titanic, uno de los conjuntos de datos mÃ¡s utilizados para introducir conceptos clave de ciencia de datos. El objetivo fue predecir la supervivencia de los pasajeros aplicando tÃ©cnicas de limpieza de datos, visualizaciÃ³n y aprendizaje automÃ¡tico. El proyecto muestra competencias en anÃ¡lisis exploratorio, manipulaciÃ³n de datos con Python, visualizaciÃ³n con seaborn y modelado con scikit-learn.



## ğŸ“Š Proyecto: PredicciÃ³n de Supervivencia en el Titanic

### ğŸ” DescripciÃ³n del problema

El objetivo es predecir si un pasajero sobreviviÃ³ al hundimiento del Titanic en base a informaciÃ³n como clase, edad, sexo, nÃºmero de familiares a bordo, entre otros.

* **Dataset fuente:** [Kaggle - Titanic: Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)



### âš™ï¸ MetodologÃ­a

1. **ExploraciÃ³n de datos**

   * InspecciÃ³n de estructura (`df.info()`) y estadÃ­sticas (`df.describe()`).
   * IdentificaciÃ³n de valores nulos y outliers.

2. **Limpieza y transformaciÃ³n**

   * ImputaciÃ³n de variables faltantes como `Age` y `Embarked`.
   * EliminaciÃ³n de columnas irrelevantes como `Cabin` y `Ticket`.
   * CodificaciÃ³n de variables categÃ³ricas (`Sex`, `Embarked`).

3. **VisualizaciÃ³n**

   * AnÃ¡lisis de supervivencia segÃºn variables claves con `seaborn` y `matplotlib`.

4. **Modelado predictivo**

   * DivisiÃ³n del dataset (entrenamiento y validaciÃ³n).
   * Entrenamiento con `LogisticRegression` y `RandomForestClassifier`.
   * EvaluaciÃ³n de modelos con mÃ©tricas como accuracy, matriz de confusiÃ³n y AUC.



### ğŸ“ˆ Resultados

* **Modelo mÃ¡s preciso:** Random Forest
* **PrecisiÃ³n obtenida:** 83%
* **Variables mÃ¡s relevantes:** `Sex`, `Pclass`, `Fare`, `Age`, `SibSp`

Ejemplo de cÃ³digo usado:

```python
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)
print(model.score(X_test, y_test))  # Output: 0.83
```



### ğŸ§  ReflexiÃ³n personal

Este proyecto me permitiÃ³ aplicar todo el ciclo de trabajo en ciencia de datos, desde la limpieza hasta el modelado. AprendÃ­ a seleccionar variables relevantes, probar diferentes algoritmos y comunicar resultados con claridad. Me interesa seguir profundizando en el uso de pipelines y validaciÃ³n cruzada.



## ğŸ› ï¸ Habilidades TÃ©cnicas

* **Lenguajes:** Python, SQL
* **LibrerÃ­as:** pandas, numpy, seaborn, matplotlib, scikit-learn, xgboost
* **Entornos:** Jupyter, Google Colab, GitHub



## ğŸ”— Recursos y enlaces

* [ğŸ”— Repositorio en GitHub](https://github.com/fralfaro/titanic-data-science-portfolio)
* [ğŸ“˜ Tutorial de Kaggle](https://www.kaggle.com/code/startupsci/titanic-data-science-solutions)
* [ğŸ§ª Competencia original en Kaggle](https://www.kaggle.com/competitions/titanic)
* [ğŸ“š DocumentaciÃ³n de scikit-learn](https://scikit-learn.org/stable/)

